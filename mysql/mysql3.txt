mysql并发问题：
1：同一时刻，如果有多个连接对同一个数据进行读写，将会造成并发问题；
2：mysql处理并发问题集中在两个层面：服务器层面和存储引擎层面
3：解决并发对数据操作结果产生影响的方式：加锁
	1：共享锁(读锁)：
		当前连接：可读，不可写（不可插入新数据，不可更新数据，不可删除数据）
		其他连接：可读，不可写（不可插入新数据，不可更新数据，不可删除数据）
	2：排它锁(写锁)：
		当前连接：可读，可写（可插入新数据，可更新数据，可删除数据）
		其他连接：不可读，不可写（不可插入新数据，不可更新数据，不可删除数据）
4：锁的粒度大小：
	锁粒度越大将会锁定的面积更大=>影响更多数据的读写，对于并发性能不好
	锁粒度越小锁定的面积将会越小=>受影响的数据面小，对于并发性能比较好

5：锁系统对性能的影响：
	数据的加锁，检查是否释放锁，释放锁，对于系统而言，都将是开销！
	不同的锁策略将带来不同的锁复杂度，进而对系统产生不同的性能影响！
	对于mysql而言，不同的存储心情会有不同的锁策略和锁粒度！
6：mysql中的锁策略和锁粒度：
	表锁：
		粒度：表锁的粒度很大，是整张表；
		开销：较小
	行级锁：
		粒度：之锁定指定数据行，粒度较小
		开销：较大；
		备注：行级锁只在存储引擎层实现；mysql服务器层并未实现行级锁；
7：谈锁离不开mysql的事务：
	事务：一组原子性的sql查询组成的一个独立的工作单元；这个工作单元满足这样的特性：
			这个工作单元中每一条sql都执行成功，那么就执行该组查询；如果其中一条sql执行失败，那么所有语句都不会执行（事务中的语句要么全部执行成功！要么全部执行失败！）；

	事务必须满足的基本特征(ACID)：
		1：A：原子性：一个事务必须被视为一个独立的不可再分割的最小的工作单元，整个事务中的所有操作要么全部成功，要么全部失败！

		2：C：一致性：即执行事务前后不能影响数据在逻辑上的合理性；事务执行成功也罢，失败也罢对于数据本身而言必须符合业务逻辑！

		3：I：隔离性：一个事务所做的修改在最终提交以前，对其他事务是不可见的！也就是说，一个事务正在操作数据库中的数据，但是这个事务在没有提交之前对于其他事务而言是不存在的；

		4：D：持久性：一旦事务提交，其所作的修改就会永久保存到数据库汇总，此时即使系统崩溃，事务所提交的修改也不能被影响！
	
	事务中的隔离级别：
		sql标准中定义了四中隔离级别：事务的隔离级别指的是事务与事务之间数据的可见性！
			级别越低：开销越小，性能越好，但是隔离性越差
			级别越高：开销越大，性能越差，但是隔离性越好
		隔离级别1：未提交读(READ UNCOMMITTED)：
			该级别最低；开销最并不会比其他级别好太多，隔离性最差；
			事务之间数据的可见性最高：事务即便没有提交，对其他事务也是可见的：即会产生脏读现象；
			(一个正在进行中的事务读取到的数据是另一个正在对改数据修改但是未提交的事务所修改后的数据)
		
		隔离级别2：提交读(READ COMMITTED):
			提交读级别：满足事务隔离性的基本定义：一个事务在对数据修改之后，如果未提交，对于其他正在进行中的事务是不可见的！
			(一个正在进行中的事务A如果对数据做了修改，但是没有提交，那么另一个正在进行中的事务B读取到是未被修改之前的数据，只有在上一个事务A提交之后，事务B读取到的数据将会是A修该之后的数据)
			该隔离级别在执行时间短的事务提交修改之后，对于执行时间长的事务如果再次读取源数据将会出现前后两次读物到的数据不一致的现象！
			该问题也被称作不可重复读！
		隔离级别3：可重复度(REPEATABLE READ)：
			该隔离级别是mysql的默认隔离级别：
			该隔离级别通过读锁和写锁解决了不可重复读的问题！
			但是对于多行数据而言，会出现幻读现象！

		隔离级别4：可串行化(SERIALIZABLE)：
			该隔离级别要求多个事务串行执行：即一个事务执行完毕之后，另一个事务才能开始执行；
			该隔离级别解决：脏读，不可重复读，幻读问题；
			但是该隔离级别最高，性能也较差！因为是串行话执行，因此也就不存在并发！
		隔离级别是通过锁来实现的！
8：死锁：
	死锁是指两个或者多个事务在同一资源上互相占用，并请求锁定对方占用的资源，从而导致恶性循环的现象；
	一般来说：当多个事务视图以不同顺序锁定资源时，大概率会产生死锁！
	如： START TRANSACTION
		UPDATE tablea SET age=12 WHERE id = 4;
		UPDATE tablea SET age=12 WHERE id = 3;
		COMMIT

		START TRANSACTION
		UPDATE tablea SET age=12 WHERE id = 3;
		UPDATE tablea SET age=12 WHERE id = 4;
		COMMIT
	innodb处理死锁的方式：将持有最少行级排它锁的事务进行回滚；

9：事务日志：
	使用事务日志可以提高事务执行效率：
		原因在于：如果使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中；而不用每次都将修改的数据本身持久到磁盘中
	事务日志采用的是AOF的方式(追加的方式)，写日志是一小块内存区域的顺序io，而不像随机io需要在磁盘的多个地方移动磁头；
	如果在事务日志记录完成之后，系统崩溃，当系统重启之后事务日志的操作记录将会被重新吧日志中的修改刷回磁盘！

10：mysql对于事务的支持：
	mysql目前对于InnoDb引擎可以使用事务，对于Myisam则不支持事务！








innodb引擎：
	1：事务：
		一组sql处理逻辑组成的一个操作单元称为事务；
	2：事务具备以下特征：
        
        一致性（Consistent）：
        	a：在事务开始和完成时，数据都必须保持一致状态。即数据必须在语义上是完整且有意义的；
        	b：该特性是事务的基本属性，也是创建事务的目标；
        	c：其余三个属性都是为了保证数据在逻辑上的一致且合理；

        原子性（Atomicity）：
        	a：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行。
        	b：该属性基本在语法层面约束了数据库中数据在语义上的一致性；
        	c：数据库通过日志的方式来保证事务的原子性；
        	c：问题：
        		在多个事务并行执行的情况下，原子性是无法保证数据的一致且合理的；此时即要使用到隔离性来进一步保证事务在执行前后，数据在语义上的一致且合理；
		隔离性（Isolation）：
			a：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的“独立”环境执行。即多个事务并发执行的结果和顺序执行的结果是一致的；
			b：mysql通过锁来实现事务的隔离性：
				b1：即通过悲观锁实现；（性能影响因素：粒度，性质;死锁：两阶段锁协议和死锁检测）
				b2：通过乐观锁：
					1：通过日志undo的方式来获取数据的历史版本，
					2：通过在内存中保存同一行数据的多个历史版本；通过事件戳来区分；
		
		持久性（Durable）：事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。
	3：事务并发+++锁：
		并发事务带来的问题：
			1：更新丢失：
				A和B在并发执行事务的过程中有可能产生更新丢失，A和B都有肯能产生更新丢失；
				B的更新丢失：
					A事务在读取原始数据，在对数据操作之后，写入数据库之前；
					B事务更改了原始数据的值，
					此时A事务再向数据库中写入操作后的结果，那么事务B的数据将会被覆盖；
				A的更新丢失：
					A事务和B事务读取了同一个原始数据，在A事务将最终结果写回数据库之后，B事务又将自己的最终结果写回数据库，最终造成A的更新数据丢失；
				排它锁即可解决上述问题
			2：脏读：
			读取了事务进行期间且事务未提交之前写入数据库的数据；称为脏读；
			(因为此时的数据有可能不具备数据的一致性)
				使用共享锁+排它锁即可解决上述问题

			3：不可重复读：
				即在同一个事务中，前后读取的同一个数据不一致，甚至数据已经被删；(根本原因是锁的问题)；
				使用排它锁+更新后的共享锁即可解决上述问题；
			4：幻读：
				一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，此时读取到的数据是新数据，这种现象就称为“幻读”。
				要解决上述问题：串行执行；
	4：事务的隔离级别：
		更新丢失			事务之间毫无隔离				应用和数据库的排它锁共同解决；
		脏读				事务之间只有写隔离				使用共享锁+排它锁解决
		不可重复读 			读和写隔离不彻底 				使用排它锁+事务级别的共享锁解决（mysql内部是事务级别的共享锁）
		幻读 				锁的粒度太小(仅锁住了当前行)	必须序列化进行操作		

		隔离级别和影响的关系：
										读数据一致性		脏读	不可重复读 		幻读   
		未提交读（Read uncommitted）	最低级别			是 		是 				是 		
		已提交读（Read committed）		语句级				否		是 				是 		
		可重复读（Repeatable read）		事务级 				否		否				是
		可序列化（Serializable）		最高级别，事务级	否		否				否

		mysql支持上述四个隔离级别；

	5：innodb行锁争用；
		可以通过检查innoDB_row_lock状态变量来分析系统上的行所争夺情况：
		a：如果innodb_row_lock_waits和innodb_row_lock_time_avg的值比较高一般代表此时锁争用比较严重；
			（show status like 'innodb_row_lock%';）
		b：可以设置innodb monitors来进一步观察发生的锁冲突的表，数据行来分析锁争用的原因：
			（CREATE TABLE innodb_monitor(a INT) ENGINE=INNODB;）
	6：innodb引擎的行锁加锁模式及加锁方法

	innodb提供的锁类型：
		nnoDB实现了以下两种类型的行锁。
		共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。
		排他锁（X)：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。

		为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁。

		意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。
		意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。

		锁和多版本数据是innodb引擎实现事务隔离性的一种手段
		其中：
			意向锁是innodb自动加的，无需用户干预；
			对于update/delete/insert操作innodb会自动给涉及的数据集加上排它锁
			对于select语句innodb不会加任何锁；
			事务可以通过以下两种方式加锁：
			¡  共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。
			¡  排他锁（X)：SELECT * FROM table_name WHERE ... FOR UPDATE。

			说明：
				用SELECT ... IN SHARE MODE获得共享锁，主要用在需要数据依存关系时来确认某行记录是否存在，并确保没有人对这个记录进行UPDATE或者DELETE操作。但是如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁，对于锁定行记录后需要进行更新操作的应用，应该使用SELECT... FOR UPDATE方式获得排他锁。
	innodb加锁实践：
		1：加共享锁：当前连接可读，可写；其他连接不加共享锁的情况下可读，不可写；
										 其他连接加共享锁的情况下，可读，不可写，且当前连接亦不可写；

		2：加排它锁：当前连接可读，可写；其他连接不加共享锁的情况下可读，不可写；
										 其他连接加共享锁的情况下，处于等待状态
										 其他连接加排他锁的情况下，处于等待状态；
	innodb加锁原理：
		1：mysql的innodb加锁是给索引上的索引项加锁来实现的，而非给整行数据加锁，因此只有通过索引条件检索数据，innodb才使用行级锁，否则innodb将使用表锁；
		在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能；

		2：由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。

		3：当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。

		4：即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。此时如果有并发，则会影响到并发；（所以在分析锁冲突时要考虑看一下生成的执行计划，来查看锁冲突的具体信息）；

	间隙锁：
		1：在使用范围条件而非相等条件检索数据的时候，innodb不但会为符合条件而且存在的数据行加锁，也会为符合条件但数据不存在的行加锁；为数据不存在但符合条件的数据加的锁称为间隙锁；

		2：间隙锁的主要作用就是为了防止幻读；但是该锁在防止幻读的优势下会引发满足符合条件的新数据无法插入；造成严重的锁等待；
		（优化：在并发插入比较多的情况下，尽量使用相等的条件来筛选数据，避免使用范围条件，而造成大批量的数据无法插入）

		3：使用相等条件给一个不存在的数据行加锁，该数据行同样也会被加上间隙锁；

	恢复和复制：
		1：mysql通过binlog来记录执行成功的insert,update,delete等更新表的sql语句，其中数据库的恢复和主从复制就是基于binlog来进行的；

		2：INSERT...SELECT...和 CREATE TABLE...SELECT...语句，可能会阻止对源表的并发更新，造成对源表锁的等待。如果查询比较复杂的话，会造成严重的性能问题，我们在应用中应尽量避免使用。实际上，MySQL将这种SQL叫作不确定（non-deterministic）的SQL，不推荐使用。

		3：原因在于上述执行方式mysql会对select后面的数据行加上共享锁，来保持binlog的日志和客户端的操作是一致的；但是此种操作又会造成源表的锁定，进而造成性能问题；

		4： mysql的该变量innodb_locks_unsafe_for_binlog的值设置为on将会关闭对源表的锁，有可能将会造成日志和实际客户端的操作不一致，进而影响主从复制和mysql的恢复；

		5：如果需要按照上述方式来满足业务需求则需要通过使用“select * from source_tab ... Into outfile”和“load data infile ...”语句组合来间接实现，采用这种方式MySQL不会给source_tab加锁。

	一般情况下，数据的一致性和事务的并发性能是成反比的，数据一致性越好，隔离级别就会越高，事务的并发性能就会越差；

	所以在写sql的时候要尽量使用范围更小的条件，充分利用索引，避免索引失效的现象，能够通过应用层面解决的问题，不要遗留到数据库层面来减小数据库锁的级别；

	innodb引擎中行锁和表锁的选择：

		1：正常情况下innodb引擎都应该使用行锁；来提高事务的并发能力；

		以下几种情况推荐使用表锁：

		1：如果事务需要更新大面积的数据，表也比较大，此时推荐使用表锁；如果使用行锁，该事务执行效率将会降低；而且可能造成其他事务长时间的锁等待和锁冲突；

		2：如果事务比较复杂，涉及多个表，引起死锁的可能性会比较大，进而造成大量事务回滚。这种情况也可以考虑一次性锁定所有的表。避免死锁，提高事务执行的成功率；

		上述两种情况尽量在业务层避免，如果使用过多就要考虑换成myisam表；

		加表锁时的注意事项：
			1：使用LOCK TABLES可以给innodb加表锁，但是该表锁是mysqlserver负责的；并不是由innodb引擎负责的，因此必须设置autocommit=0;且innodb_tables_locks=1；否则innodb无法处理该种表级死锁；

			2：LOCK TABLES的解锁必须使用UNLOCK TABLES;commit和rollback是无法释放表锁的；也不要在事务没有完成之前使用UNLOCK TABLES释放表锁，原因在于UNLOCK TABLES隐含有commit的操作；

	innodb引擎中的死锁：
		MyISAM表锁是deadlock free的；因为MyISAM总是一次获得所需要的全部锁，要么全部满足，要么全部等待，因此不会出现死锁；

		innodb获取锁是逐步获取的，因此死锁极有可能发生的；
		innodb一般可以检测到死锁，此时会使一个事务回退，让另一个事务获取锁，继续完成事务；
		innodb引擎如果涉及到外部锁，或者涉及到表锁的情况下，innodb并不能完全自动检测到死锁；此时将需要设置锁等待参数innodb_lock_wait timeout来解决；

		注意：innodb_lock_wait_timeout并不是用来解决死锁问题的，在并发比较高的情况下，如果大量事务无法立即获取所需要的锁而挂起将会占用大量的计算机资源，造成严重的性能问题；甚至拖垮数据库；

		解决方式：
			1：在应用中如果牵扯到多个应用并发存取多个表，应尽量约定以相同的顺序访问表；
			2：如果程序是批量的方式处理数据，如果事先对数据排序，保证每个线程按固定的顺序来处理记录；

			3：在REPEATABLE-READ隔离级别下，如果两个线程同时对相同条件记录用SELECT...FOR UPDATE加排他锁，在没有符合该条件记录情况下，两个线程都会加锁成功。程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁。这种情况下，将隔离级别改成READ COMMITTED，就可避免问题

			4：当隔离级别为READ COMMITTED时，如果两个线程都先执行SELECT...FOR UPDATE，判断是否存在符合条件的记录，如果没有，就插入记录。此时，只有一个线程能插入成功，另一个线程会出现锁等待，当第1个线程提交后，第2个线程会因主键重出错，但虽然这个线程出错了，却会获得一个排他锁！这时如果有第3个线程又来申请排他锁，也会出现死锁。对于这种情况可以直接做插入操作，然后再捕获主键重复异常；或者在遇到主键重复错误时总是执行rollback来释放获得的排他锁；

			死锁发生后一般可以使用show innodb status命令来确定一个死锁产生的详细信息；

	小结
	本章重点介绍了MySQL中MyISAM表级锁和InnoDB行级锁的实现特点，并讨论了两种存储引擎经常遇到的锁问题和解决办法。
	对于MyISAM的表锁，主要讨论了以下几点：
	（1）共享读锁（S）之间是兼容的，但共享读锁（S）与排他写锁（X）之间，以及排他写锁（X）之间是互斥的，也就是说读和写是串行的。
	（2）在一定条件下，MyISAM允许查询和插入并发执行，我们可以利用这一点来解决应用中对同一表查询和插入的锁争用问题。
	（3）MyISAM默认的锁调度机制是写优先，这并不一定适合所有应用，用户可以通过设置LOW_PRIORITY_UPDATES参数，或在INSERT、UPDATE、DELETE语句中指定LOW_PRIORITY选项来调节读写锁的争用。
	（4）由于表锁的锁定粒度大，读写之间又是串行的，因此，如果更新操作较多，MyISAM表可能会出现严重的锁等待，可以考虑采用InnoDB表来减少锁冲突。
	对于InnoDB表，本章主要讨论了以下几项内容。
	l         InnoDB的行锁是基于锁引实现的，如果不通过索引访问数据，InnoDB会使用表锁。
	l         介绍了InnoDB间隙锁（Next-key)机制，以及InnoDB使用间隙锁的原因。
	l         在不同的隔离级别下，InnoDB的锁机制和一致性读策略不同。
	l         MySQL的恢复和复制对InnoDB锁机制和一致性读策略也有较大影响。
	l         锁冲突甚至死锁很难完全避免。
	在了解InnoDB锁特性后，用户可以通过设计和SQL调整等措施减少锁冲突和死锁，包括：
	l         尽量使用较低的隔离级别；
	l         精心设计索引，并尽量使用索引访问数据，使加锁更精确，从而减少锁冲突的机会；
	l         选择合理的事务大小，小事务发生锁冲突的几率也更小；
	l         给记录集显示加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁；
	l         不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大大减少死锁的机会；
	l         尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响；
	l         不要申请超过实际需要的锁级别；除非必须，查询时不要显示加锁；
	l         对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能。


















